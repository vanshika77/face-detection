# -*- coding: utf-8 -*-
"""training_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GysvdYEuvSZNGzsfUlCHMHdL6eo50u74
"""

from google.colab import drive
drive.mount("/content/gdrive")

import numpy as np
import os
import cv2
from tqdm import tqdm

DATADIR = r"/content/gdrive/My Drive/faces"

CATEGORIES = ['1', '2', '3', '4', '5']

IMG_SIZE =150
img_rows, img_cols = 150,150
training_data = []

def create_training_data():
    for category in CATEGORIES:
        
        path = os.path.join(DATADIR,category)
        class_num = CATEGORIES.index(category)
        
        for img in tqdm(os.listdir(path)):
            try:
                img_array = cv2.imread(os.path.join(path,img))
                new_array = cv2.resize(img_array,(IMG_SIZE, IMG_SIZE))
                training_data.append([new_array, class_num]) 
            except Exception as e:
                pass

create_training_data()

print(len(training_data))

X = []
y = []

for features,label in training_data:
    X.append(features)
    y.append(label)

X1 = np.array(X)
X1.shape

y = np.array(y)
y.shape

from sklearn.model_selection import train_test_split
from keras.utils import np_utils

X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=4)
X_train = X_train.reshape(X_train.shape[0],img_rows, img_cols,3)
X_test = X_test.reshape(X_test.shape[0],img_rows, img_cols,3)

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

X_train /= 255
X_test /= 255

Y_train = np_utils.to_categorical(y_train, 5)
Y_test = np_utils.to_categorical(y_test, 5)

X_test.shape

Y_train.shape

from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense

cnn = Sequential()

#step -1
cnn.add(Convolution2D(32, 3, 3, input_shape = (150, 150, 3), activation = 'relu'))

#step-2
cnn.add(MaxPooling2D(pool_size = (2,2)))

cnn.add(Convolution2D(64, 3, 3, activation = 'relu'))

#step-2
cnn.add(MaxPooling2D(pool_size = (2,2)))

#step-3
cnn.add(Flatten())

#step-4
cnn.add(Dense(units = 2048, activation = 'relu'))
cnn.add(Dense(units = 512, activation = 'relu'))
cnn.add(Dense(units = 5, activation = 'softmax'))

#step -5
cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])

cnn.summary()

hist = cnn.fit(X_train, Y_train, batch_size =32, epochs = 20,
               verbose =1, validation_split =0.2)

# evaluate the model
scores = cnn.evaluate(X_train, Y_train, verbose=0)
print("%s: %.2f%%" % (cnn.metrics_names[1], scores[1]*100))
# save model and architecture to single file
cnn.save("/content/gdrive/My Drive/model/f.h5")
print("Saved model to disk")